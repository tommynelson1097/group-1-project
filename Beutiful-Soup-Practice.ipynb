{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be03e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url  = 'https://avinashjairam.github.io/example2.html'\n",
    "\n",
    "# make a request to server\n",
    "\n",
    "headers = {\n",
    "            'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'\n",
    "          }\n",
    "\n",
    "page = requests.get(url, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe21c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<html>\\n <head>\\n  <title>\\n   Example 2\\n  </title>\\n </head>\\n <body>\\n  <h1>\\n   Example 2\\n  </h1>\\n  <p>\\n   The cat in the hat\\n  </p>\\n  <h2>\\n   Here's another sentence\\n  </h2>\\n  <p>\\n   The cow jumped over the moon.\\n  </p>\\n  <h1>\\n   Here's another sentence\\n  </h1>\\n  <p>\\n   Mary had a little lamb\\n  </p>\\n </body>\\n</html>\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code # success connecting to the main server\n",
    "\n",
    "\n",
    "# goal is to extract the content of all h1 tags\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5855c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2\n",
      "Here's another sentence\n",
      "The cat in the hat\n",
      "The cow jumped over the moon.\n",
      "Mary had a little lamb\n",
      "Here's another sentence\n"
     ]
    }
   ],
   "source": [
    "h1_tags = soup.findAll('h1')\n",
    "h1_tags\n",
    "\n",
    "for h1_tag in h1_tags:\n",
    "    print(h1_tag.get_text()) # extracts the data for h1 tags  \n",
    "\n",
    "p_tags = soup.find_all('p') # list of all paragraph tags\n",
    "\n",
    "for p_tag in p_tags:\n",
    "    print(p_tag.get_text())\n",
    "\n",
    "h2_tags = soup.find_all('h2') # list of all paragraph tags\n",
    "\n",
    "for h2_tag in h2_tags:\n",
    "    print(h2_tag.get_text()) # selecting the h2 tag \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59654648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "soup.find_all('h3') # no h3 is present in the source code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d7235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>CIS 3120 SYLLABUS&gt;</title>\n",
       "</head>\n",
       "<body>\n",
       "<h4>Instructor:</h4>\n",
       "<p id=\"instructor\"> Mr. Avinash Jairam </p>\n",
       "<h4>Class Time: </h4>\n",
       "<p id=\"time\"> Saturday: 11:10AM - 2:05PM - ONLINE via BlackBoard Collaborate </p>\n",
       "<h4>Office hours:</h4>\n",
       "<p id=\"office_hours\"> Saturday: 1:00PM - 3:00PM </p>\n",
       "<h4>Email:</h4>\n",
       "<p id=\"email\"> avinash.jairam@baruch.cuny.edu </p>\n",
       "<h4>Course Website :</h4>\n",
       "<p id=\"website\"> Blackboard</p>\n",
       "<h4>Course Description:</h4>\n",
       "<p id=\"description\">\n",
       "\t This course introduces the aspects of programming that can\n",
       "\tsupport business analytics. The course covers hands-on issues in programming for\n",
       "\tanalytics which include accessing data, \n",
       "\tcreating informative data graphics, writing functions, \n",
       "\tdebugging, and organizing and commenting code.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_2 = 'https://avinashjairam.github.io/syllabus.html'\n",
    "\n",
    "headers = {\n",
    "            'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'\n",
    "          }\n",
    "\n",
    "page_2 = requests.get(url_2, headers = headers)\n",
    "page_2.status_code\n",
    "soup = BeautifulSoup(page_2.content, 'html.parser')\n",
    "soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5017c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "50\n",
      "340\n",
      "50\n",
      "10\n",
      "5\n",
      "210\n",
      "54\n",
      "20\n",
      "0\n",
      "400\n",
      "2\n",
      "103.42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "url_2 = 'https://avinashjairam.github.io/tableExample1.html'\n",
    "\n",
    "headers = {\n",
    "            'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'\n",
    "          }\n",
    "\n",
    "page_2 = requests.get(url_2, headers = headers)\n",
    "page_2.status_code\n",
    "soup = BeautifulSoup(page_2.content, 'html.parser')\n",
    "soup\n",
    "\n",
    "\n",
    "tr_tags = soup.find_all('tr') # list of all paragraph tags\n",
    "tr_list = []\n",
    "\n",
    "for tr_tag in tr_tags:\n",
    "    # print(tr_tag.get_text()) # selecting the h2 tag \n",
    "    tr_list.append(tr_tag.get_text())\n",
    "\n",
    "list_2 = []\n",
    "\n",
    "for tr in tr_list:\n",
    "    new_field = tr.split('\\n')\n",
    "    list_2.append(new_field)\n",
    "\n",
    "num_list = []\n",
    "\n",
    "for n in list_2:\n",
    "    if n[2] != 'Savings': \n",
    "      val = n[2].replace(\"$\",\"\")\n",
    "      num_list.append(int(val))\n",
    "      print(val)\n",
    "\n",
    "avg_val = round(sum(num_list) / len(num_list),2) \n",
    "print(avg_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof Jairam's approach for python scraping tables \n",
    "import numpy as np  \n",
    "import requests\n",
    "\n",
    "url_2 = 'https://avinashjairam.github.io/tableExample1.html'\n",
    "\n",
    "headers = {\n",
    "            'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'\n",
    "          }\n",
    "\n",
    "page_2 = requests.get(url_2, headers = headers)\n",
    "page_2.status_code\n",
    "soup = BeautifulSoup(page_2.content, 'html.parser')\n",
    "soup\n",
    "\n",
    "table_tags = soup.find_all('table') # list of all paragraph tags\n",
    "my_table = table_tags[0] # grabbing table \n",
    "\n",
    "tr_tags = soup.findAll('tr')\n",
    "\n",
    "tr_tags # look at first vs second cell and compare\n",
    "\n",
    "month_list = []\n",
    "money_list = []\n",
    "\n",
    "for row in tr_tags:\n",
    "      if len(row.find_all('td')) == 0:\n",
    "        continue\n",
    "\n",
    "      month_list.append(row.find_all('td')[0].get_text())\n",
    "      money_list.append(float(row.find_all('td')[1].get_text()[1:])) \n",
    "\n",
    "\n",
    "#create a dictionary in pyhon - two keys - each key represents a column\n",
    "\n",
    "savings_data = {\n",
    "        'Month': month_list,\n",
    "        'Savings': money_list\n",
    "  }\n",
    "\n",
    "df = pd.DataFrame(savings_data)\n",
    "\n",
    "#export data to excel\n",
    "df.to_csv('monthly_savings.csv')\n",
    "\n",
    "\n",
    "# print(df['Savings'])\n",
    "# df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
